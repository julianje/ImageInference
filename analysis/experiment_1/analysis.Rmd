---
title: "Image Inference - Experiment 1"
output:
  html_document:
    code_folding: hide
    df_print: paged
  pdf_document: default
---

```{r setup, echo=FALSE}
# Set the working directory.
knitr::opts_knit$set(root.dir=normalizePath("../.."))

# Turn off compile messages and warnings.
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```

```{r echo=FALSE}
# Import R libraries.
library(boot)
library(corrplot)
library(jsonlite)
library(tidyverse)
```

# Pilot
<!--
#### pilot_4

Swapped out the cookie for I thought I had the wrong stimuli for `PX_PX_0`, but it turns out that was the right one. I ended up cancelling the task at $n=14$.

#### pilot_5

Revised the introduction. 

#### pilot_6
-->
```{r, echo=FALSE}
# Set up which pilot is being analyzed.
pilot_path = "data/experiment_1/data_0"

# Read in the participant data (after manually removing errors).
data_0 <- read_csv(file.path(pilot_path, "raw_data.csv"), quote="~")

# Read in the MTurk results file.
# mturk_results = read_csv(file.path(pilot_path, "mturk_results.csv"), col_names=TRUE) %>%
#   mutate(Answer.surveycode=substr(Answer.surveycode, 3, length(Answer.surveycode)))

# Filter out any duplicate database entries based on the MTurk results file.
# duplicates <- setdiff(data_0$UniqueId, mturk_results$Answer.surveycode)
# data_1 <- data_0 %>%
#   filter(!(UniqueId %in% c("ll email completio", "yYCyou3")))

# Convert the JSON string into JSON.
data_1 = lapply(data_0$Results, fromJSON)

# Extract the trial information for each participant and stack them.
data_3 = tibble()
for (p in 1:length(data_1)) {
  # Trim the map and add the participant ID back in.
  data_2 = data_1[p][[1]]$trials %>%
    as.data.frame() %>%
    mutate(map=gsub(".png", "", map), unique_id=data_0$UniqueId[p],
           wrong_attempts=data_1[p][[1]]$catch_trials$wrong_attempts)

  # Stack the trial information for the current participant.
  data_3 = rbind(data_3, data_2)
}

# Write the preprocessed data.
# write_csv(data_3, file.path(pilot_path, "data.csv"))
```

## Goal Predictions

```{r, fig.align="center"}
# Read in the preprocessed data.
data_3 = read_csv(file.path(pilot_path, "data.csv"))

# Select and normalize the goal judgments.
data_4 = data_3 %>%
  select(unique_id, map, A, B, C) %>%
  gather(goal, human, A, B, C) %>%
  left_join(do(., summarize(group_by(., unique_id, map),
                            total_human=sum(human)))) %>%
  mutate(human=human/total_human) %>%
  select(-total_human)

# Define the bootstrap function for the bootstrap statistic.
compute_mean = function(data, indices) {
  return(mean(data[indices]))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_mean,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
ci = data.frame()
for (m in unique(data_4$map)) {
    # Compute the bootstrap for each dependent measure.
    A_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="A")$human)
    B_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="B")$human)
    C_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="C")$human)
    
    # Store the bootstrapped 95% CIs for this pair.
    ci = rbind(ci, data.frame(map=rep(m, 3),
                              goal=c("A", "B", "C"),
                              lower=c(A_bootstrap[4], B_bootstrap[4], C_bootstrap[4]),
                              upper=c(A_bootstrap[5], B_bootstrap[5], C_bootstrap[5])))
}

# Read in the goal predictions.
model_0 = read_csv("data/model/predictions/Manhattan/goal_predictions.csv")

# Perform some basic preprocessing and then z-score the model predictions.
model_1 = model_0 %>%
  select(-Goal) %>%
  rename(goal=GoalLetter, map=Trial, model=Probability) %>%
  mutate(z_model=scale(model))

# Merge the human and model data. # Join the bootstrapped 95% CIs with the normalized participant judgments.
data_5 = data_4 %>%
  group_by(unique_id) %>%
  mutate(z_human=scale(human)) %>%
  ungroup() %>%
  group_by(map, goal) %>%
  summarize(mean_human=mean(human), mean_z_human=mean(z_human)) %>%
  left_join(ci) %>%
  left_join(model_1)

# Plot the goal comparison.
plot_0 = data_5 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=substr(map, 0, 2))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Goal Predictions vs. Participant Goal Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Goal") + 
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5))
plot_0
```

The correlation is `r cor(data_5$model, data_5$mean_human, method="pearson")`. If we split up the data by trial, we get:

```{r, fig.align="center"}
# Plot goal inferences by trial.
plot_1 = data_5 %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=goal, y=value, group=type)) +
  geom_point(aes(color=type)) +
  geom_line(aes(color=type)) + 
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.2) +
  facet_wrap(~map) +
  xlab("Goal") +
  ylab("Value") +
  scale_color_discrete(name="Type",
                       limits=c("mean_human", "model"),
                       labels=c("Human", "Model")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_1
```

## Entrance Predictions

```{r, fig.align="center"}
# Select and normalize the entrance judgments.
data_6 = data_3 %>%
  filter(!grepl("ND", map)) %>%
  select(unique_id, map, `1`, `2`, `3`) %>%
  gather(entrance, human, `1`, `2`, `3`) %>%
  filter(human!=-1) %>%
  left_join(do(., summarize(group_by(., unique_id, map),
                            total_human=sum(human)))) %>%
  mutate(human=human/total_human) %>%
  select(-total_human)

# Define the bootstrap function for the bootstrap statistic.
compute_mean = function(data, indices) {
  return(mean(data[indices]))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_mean,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
ci = data.frame()
for (m in unique(data_6$map)) {
    # Compute the bootstrap for each dependent measure.
    bootstrap_1 = compute_bootstrap(filter(data_6, map==m, entrance=="1")$human)
    bootstrap_2 = compute_bootstrap(filter(data_6, map==m, entrance=="2")$human)
    if (length(unique(filter(data_6, map==m)$entrance)) == 3) {
      bootstrap_3 = compute_bootstrap(filter(data_6, map==m, entrance=="3")$human)
    }
    
    # Store the bootstrapped 95% CIs for this pair.
    if (length(unique(filter(data_6, map==m)$entrance)) == 3) {
      ci = rbind(ci, data.frame(map=rep(m, 3),
                                entrance=c("1", "2", "3"),
                                lower=c(bootstrap_1[4], bootstrap_2[4], bootstrap_3[4]),
                                upper=c(bootstrap_1[5], bootstrap_2[5], bootstrap_3[5])))
    }
    else {
      ci = rbind(ci, data.frame(map=rep(m, 2),
                                entrance=c("1", "2"),
                                lower=c(bootstrap_1[4], bootstrap_2[4]),
                                upper=c(bootstrap_1[5], bootstrap_2[5])))
    }
}

# Read in the entrance predictions.
model_2 = read_csv("data/model/predictions/Manhattan/entrance_predictions.csv")

# Stitch the entrance mapping to the predictions and do some preprocessing.
model_3 = model_2 %>%
  right_join(read_csv("data/model/predictions/Manhattan/entrance_mapping.csv")) %>%
  mutate(Probability=ifelse(is.na(Probability), 0, Probability)) %>%
  select(-Entrance) %>%
  rename(map=TrialName, entrance=DoorNumber, model=Probability) %>%
  mutate(entrance=as.character(entrance), z_model=scale(model))

# Select the entrance judgments, norm them, then z-score within participants.
data_7 = data_6 %>%
  group_by(unique_id) %>%
  mutate(z_human=scale(human)) %>%
  ungroup() %>%
  group_by(map, entrance) %>%
  summarize(mean_human=mean(human), mean_z_human=mean(z_human)) %>%
  left_join(ci) %>%
  left_join(model_3)

# Plot the entrance comparison.
plot_2 = data_7 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=substr(map, 0, 2))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Entrance Predictions vs. Participant Entrance Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Entrance") +
  theme_classic() + 
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5))
plot_2
```

The Pearson correlation is `r cor(data_7$model, data_7$mean_human, method="pearson")`. If we split up the data by trial, we get:

```{r, fig.align="center"}
# Plot entrance inferences by trial.
plot_3 = data_7 %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=entrance, y=value, group=type)) +
  geom_point(aes(color=type)) +
  geom_line(aes(color=type)) +
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.2) +
  facet_wrap(~map) +
  xlab("Entrance") +
  ylab("Value") +
  scale_color_discrete(name="Type",
                       limits=c("mean_human", "model"),
                       labels=c("Human", "Model")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_3
```

Finally, we can plot the goal and entrance inferences together:

```{r, fig.align="center"}
# Merge the two inferences.
data_8 = data_5 %>%
  mutate(type="goal", inference=goal) %>%
  select(-goal) %>%
  rbind(select(mutate(data_7, type="entrance", inference=entrance), -entrance))

plot_4 = data_8 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=type)) +
  # geom_text(vjust=-1.0, hjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Predictions vs. Participant Judgments") +
  xlab("Model Predictions") +
  ylab("Participant Judgments") +
  scale_color_discrete(name="Type",
                       limits=c("entrance", "goal"),
                       labels=c("Entrance", "Goal")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_4
```

The Pearson correlation is `r cor(data_8$model, data_8$mean_human, method="pearson")`.

<!-- Print model comparisons by trial: -->
<!--
```{r, eval=FALSE}
plot_set = list()
for (m in unique(arrange(data_8, map)$map)) {
  plot_5 = data_8 %>%
    filter(map==m) %>%
    gather(source, value, mean_human, model) %>%
    ggplot(aes(x=inference, y=value, group=source, color=source)) +
    geom_point() + 
    geom_line() +
    geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.2) +
    facet_wrap(~factor(type,
                       levels=c("entrance", "goal"), 
                       labels=c("Entrance", "Goal")), 
               scale="free_x") +
    xlab("Feature") +
    ylab("Inference") +
    scale_color_discrete(name="Source",
                         limits=c("mean_human", "model"),
                         labels=c("Human", "Model")) +
    theme_classic() +
    theme(legend.title=element_text(hjust=0.5))
  # plot_set = list(plot_set, plot_5)
}
```

<img src="`r file.path(getwd(), "stimuli/experiment_1/DX_DX_0.png")`" style="height:auto;width=50px;"/>

<img src="`r file.path(getwd(), "stimuli/experiment_1/DX_NX_0.png")`" style="height:auto;width=50px;"/>
-->

```{r, eval=FALSE, include=FALSE}
data_4 %>% 
  rename(type=goal) %>% 
  rbind(rename(data_5, type=entrance)) %>% 
  ggplot(aes(x=model, y=mean_human, label=map)) + 
  geom_point(aes(color=type)) +
  geom_smooth(method="lm") + 
  # ggtitle("Model Entrance Predictions vs. Participant Entrance Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Type") +
  theme_classic()

library(corrplot)
data_3 %>%
  filter(map=="ND_PX_1") %>%
  select(map, A, B, C, unique_id) %>%
  gather(goal, value, A, B, C) %>%
  ggplot(aes(x=value, fill=goal)) +
  geom_density(alpha=0.33) +
  facet_wrap(~map)
  # mutate(full_id=paste(map, goal, sep="_")) %>%
  # select(-map, -goal) %>%
  # spread(unique_id, value) %>%
  # select(-full_id) %>%
  # cor()
  # 
  # corrplot()
```