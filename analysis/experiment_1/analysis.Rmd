---
title: "Image Inference - Experiment 1"
output:
  html_document:
    code_folding: hide
    df_print: paged
  pdf_document: default
---

```{r setup, echo=FALSE}
# Set the working directory.
knitr::opts_knit$set(root.dir=normalizePath("../.."))

# Turn off compile messages and warnings.
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
```

```{r echo=FALSE}
# Import R libraries.
library(boot)
library(corrplot)
library(jsonlite)
library(tidyverse)

# Set up which data is being analyzed.
data_path = "data/experiment_1/data_0"
```

# Pilot
<!--
#### pilot_4

Swapped out the cookie for I thought I had the wrong stimuli for `PX_PX_0`, but it turns out that was the right one. I ended up cancelling the task at $n=14$.

#### pilot_5

Revised the introduction. 

#### pilot_6
-->
```{r, echo=FALSE}
# Read in the participant data (after manually removing errors).
data_0 <- read_csv(file.path(data_path, "raw_data.csv"), quote="~")

# Read in the MTurk results file.
# mturk_results = read_csv(file.path(pilot_path, "mturk_results.csv"), col_names=TRUE) %>%
#   mutate(Answer.surveycode=substr(Answer.surveycode, 3, length(Answer.surveycode)))

# Filter out any duplicate database entries based on the MTurk results file.
# duplicates <- setdiff(data_0$UniqueId, mturk_results$Answer.surveycode)
# data_1 <- data_0 %>%
#   filter(!(UniqueId %in% c("ll email completio", "yYCyou3")))

# Convert the JSON string into JSON.
data_1 = lapply(data_0$Results, fromJSON)

# Extract the trial information for each participant and stack them.
data_3 = tibble()
for (p in 1:length(data_1)) {
  # Trim the map and add the participant ID back in.
  data_2 = data_1[p][[1]]$trials %>%
    as.data.frame() %>%
    mutate(map=gsub(".png", "", map), unique_id=data_0$UniqueId[p],
           wrong_attempts=data_1[p][[1]]$catch_trials$wrong_attempts)

  # Stack the trial information for the current participant.
  data_3 = rbind(data_3, data_2)
}

# Write the preprocessed data.
# write_csv(data_3, file.path(pilot_path, "data.csv"))
```

## TEMP

```{r}
temp_1 = tibble()
for (p in 1:length(data_1)) {
  temp_0 = data.frame(
    unique_id = data_0$UniqueId[p],
    age = as.numeric(data_1[p][[1]]$subject_information$age)
  )
        
  temp_1 = rbind(temp_1, temp_0)
}
```

## Goal Predictions

```{r, fig.align="center"}
# Read in the preprocessed data.
data_3 = read_csv(file.path(data_path, "data.csv"))

# Select and normalize the goal judgments.
data_4 = data_3 %>%
  select(unique_id, map, A, B, C) %>%
  gather(goal, human, A, B, C) %>%
  left_join(do(., summarize(group_by(., unique_id, map),
                            total_human=sum(human)))) %>%
  mutate(human=human/total_human) %>%
  select(-total_human)

# Define the bootstrap function for the bootstrap statistic.
compute_mean = function(data, indices) {
  return(mean(data[indices]))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_mean,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
ci = data.frame()
for (m in unique(data_4$map)) {
    # Compute the bootstrap for each dependent measure.
    A_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="A")$human)
    B_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="B")$human)
    C_bootstrap = compute_bootstrap(filter(data_4, map==m, goal=="C")$human)
    
    # Store the bootstrapped 95% CIs for this pair.
    ci = rbind(ci, data.frame(map=rep(m, 3),
                              goal=c("A", "B", "C"),
                              lower=c(A_bootstrap[4], B_bootstrap[4], C_bootstrap[4]),
                              upper=c(A_bootstrap[5], B_bootstrap[5], C_bootstrap[5])))
}

# Read in the goal predictions.
model_0 = read_csv("data/model/predictions/Manhattan/goal_predictions.csv")

# Perform some basic preprocessing and then z-score the model predictions.
model_1 = model_0 %>%
  select(-Goal) %>%
  rename(goal=GoalLetter, map=Trial, model=Probability) %>%
  mutate(z_model=scale(model))

# Merge the human and model data. # Join the bootstrapped 95% CIs with the normalized participant judgments.
data_5 = data_4 %>%
  group_by(unique_id) %>%
  mutate(z_human=scale(human)) %>%
  ungroup() %>%
  group_by(map, goal) %>%
  summarize(mean_human=mean(human), mean_z_human=mean(z_human)) %>%
  left_join(ci) %>%
  left_join(model_1)

# Plot the goal comparison.
plot_0 = data_5 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=substr(map, 0, 2))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Goal Predictions vs. Participant Goal Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Goal") + 
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5))
plot_0
```

```{r}
# Compute the correlation and bootstrap the CIs.
compute_cor = function(data, indices) {
  return(cor(data$model[indices], data$mean_human[indices], method="pearson"))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_cor,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
ci_0 = compute_bootstrap(data_5)
ci_0[4]
ci_0[5]
```

The correlation is `r cor(data_5$model, data_5$mean_human, method="pearson")`. If we split up the data by trial, we get:

```{r, fig.align="center"}
# Plot goal inferences by trial.
plot_1 = data_5 %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=goal, y=value, group=type)) +
  geom_point(aes(color=type)) +
  geom_line(aes(color=type)) + 
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.2) +
  facet_wrap(~map) +
  xlab("Goal") +
  ylab("Value") +
  scale_color_discrete(name="Type",
                       limits=c("mean_human", "model"),
                       labels=c("Human", "Model")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_1
```

## TEMP

```{r}
left_plot = data_5 %>%
  filter(grepl("ND_", map)) %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=goal, y=value, group=type)) +
  geom_point(aes(color=type), size=1) +
  geom_line(aes(color=type), size=0.5) + 
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.4, size=0.5) +
  facet_wrap(~map, ncol=2) +
  xlab("Goal") +
  ylab("Value") +
  scale_color_discrete(name="",
                       limits=c("mean_human", "model"),
                       labels=c("", "")) +
  theme_classic() +
  theme(strip.text=element_text(size=28),
        legend.position="bottom",
        legend.title=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=10),
        axis.text=element_text(size=9))
left_plot
  
right_plot_0 = data_5 %>% 
  filter(!grepl("ND_", map)) %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=goal, y=value, group=type)) +
  geom_point(aes(color=type), size=1) +
  geom_line(aes(color=type), size=0.5) + 
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.4, size=0.5) +
  facet_wrap(~map) +
  xlab("Goal") +
  ylab("Value") +
  scale_color_discrete(name="Inference Type",
                       limits=c("mean_human", "model"),
                       labels=c("Human", "Model")) +
  theme_classic() +
  theme(strip.text=element_text(size=28),
        legend.position="bottom",
        legend.title=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=10),
        axis.text=element_text(size=9))
right_plot_0

right_plot_1 = data_7 %>% 
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=entrance, y=value, group=type)) +
  geom_point(aes(color=type), size=1) +
  geom_line(aes(color=type), size=0.5) + 
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.4, size=0.5) +
  facet_wrap(~map) +
  xlab("Entrance") +
  ylab("Value") +
  scale_color_discrete(name="",
                       limits=c("mean_human", "model"),
                       labels=c("", "")) +
  theme_classic() +
  theme(strip.text=element_text(size=28),
        legend.position="bottom",
        legend.title=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=10),
        axis.text=element_text(size=9),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
right_plot_1

figure_3 = plot_grid(left_plot, right_plot_0, right_plot_1, rel_widths=c(0.25, 0.41, 0.34), nrow=1)
```

## Entrance Predictions

```{r, fig.align="center"}
# Select and normalize the entrance judgments.
data_6 = data_3 %>%
  filter(!grepl("ND", map)) %>%
  select(unique_id, map, `1`, `2`, `3`) %>%
  gather(entrance, human, `1`, `2`, `3`) %>%
  filter(human!=-1) %>%
  left_join(do(., summarize(group_by(., unique_id, map),
                            total_human=sum(human)))) %>%
  mutate(human=human/total_human) %>%
  select(-total_human)

# Define the bootstrap function for the bootstrap statistic.
compute_mean = function(data, indices) {
  return(mean(data[indices]))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_mean,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
ci = data.frame()
for (m in unique(data_6$map)) {
    # Compute the bootstrap for each dependent measure.
    bootstrap_1 = compute_bootstrap(filter(data_6, map==m, entrance=="1")$human)
    bootstrap_2 = compute_bootstrap(filter(data_6, map==m, entrance=="2")$human)
    if (length(unique(filter(data_6, map==m)$entrance)) == 3) {
      bootstrap_3 = compute_bootstrap(filter(data_6, map==m, entrance=="3")$human)
    }
    
    # Store the bootstrapped 95% CIs for this pair.
    if (length(unique(filter(data_6, map==m)$entrance)) == 3) {
      ci = rbind(ci, data.frame(map=rep(m, 3),
                                entrance=c("1", "2", "3"),
                                lower=c(bootstrap_1[4], bootstrap_2[4], bootstrap_3[4]),
                                upper=c(bootstrap_1[5], bootstrap_2[5], bootstrap_3[5])))
    }
    else {
      ci = rbind(ci, data.frame(map=rep(m, 2),
                                entrance=c("1", "2"),
                                lower=c(bootstrap_1[4], bootstrap_2[4]),
                                upper=c(bootstrap_1[5], bootstrap_2[5])))
    }
}

# Read in the entrance predictions.
model_2 = read_csv("data/model/predictions/Manhattan/entrance_predictions.csv")

# Stitch the entrance mapping to the predictions and do some preprocessing.
model_3 = model_2 %>%
  right_join(read_csv("data/model/predictions/Manhattan/entrance_mapping.csv")) %>%
  mutate(Probability=ifelse(is.na(Probability), 0, Probability)) %>%
  select(-Entrance) %>%
  rename(map=TrialName, entrance=DoorNumber, model=Probability) %>%
  mutate(entrance=as.character(entrance), z_model=scale(model))

# Select the entrance judgments, norm them, then z-score within participants.
data_7 = data_6 %>%
  group_by(unique_id) %>%
  mutate(z_human=scale(human)) %>%
  ungroup() %>%
  group_by(map, entrance) %>%
  summarize(mean_human=mean(human), mean_z_human=mean(z_human)) %>%
  left_join(ci) %>%
  left_join(model_3)

# Plot the entrance comparison.
plot_2 = data_7 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=substr(map, 0, 2))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Entrance Predictions vs. Participant Entrance Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Entrance") +
  theme_classic() + 
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5))
plot_2
```

```{r}
# Compute the correlation and bootstrap the CIs.
compute_cor = function(data, indices) {
  return(cor(data$model[indices], data$mean_human[indices], method="pearson"))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_cor,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
cor_1 = cor(data_7$model, data_7$mean_human, method="pearson")
cor_1_ci = compute_bootstrap(data_5)
cor_1_ci[4]
cor_1_ci[5]
```

The Pearson correlation is `r cor(data_7$model, data_7$mean_human, method="pearson")`. If we split up the data by trial, we get:

```{r, fig.align="center"}
# Plot entrance inferences by trial.
plot_3 = data_7 %>%
  gather(type, value, mean_human, model) %>%
  ggplot(aes(x=entrance, y=value, group=type)) +
  geom_point(aes(color=type)) +
  geom_line(aes(color=type)) +
  geom_errorbar(aes(ymin=lower, ymax=upper), color="#F8766D", width=0.2) +
  facet_wrap(~map) +
  xlab("Entrance") +
  ylab("Value") +
  scale_color_discrete(name="Type",
                       limits=c("mean_human", "model"),
                       labels=c("Human", "Model")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_3
```

Finally, we can plot the goal and entrance inferences together:

```{r, fig.align="center"}
# Merge the two inferences.
data_8 = data_5 %>%
  mutate(type="goal", inference=goal) %>%
  select(-goal) %>%
  rbind(select(mutate(data_7, type="entrance", inference=entrance), -entrance))

plot_4 = data_8 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(color=type)) +
  # geom_text(vjust=-1.0, hjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Predictions vs. Participant Judgments") +
  xlab("Model Predictions") +
  ylab("Participant Judgments") +
  scale_color_discrete(name="Type",
                       limits=c("entrance", "goal"),
                       labels=c("Entrance", "Goal")) +
  theme_classic() +
  theme(legend.title=element_text(hjust=0.5))
plot_4
```

```{r}
# Bootstrap the CI for correlation.
# Define the bootstrap function for the bootstrap statistic.
compute_cor = function(data, indices) {
  return(cor(data$model[indices], data$mean_human[indices], method="pearson"))
}

# Define the bootstrap function to simulate the data.
compute_bootstrap = function(data) {
  # Run the simulations.
  simulations = boot(data=data,
                     statistic=compute_cor,
                     R=10000)
  
  return(boot.ci(simulations, type="bca")$bca)
}

# Compute the bootstrapped 95% CIs.
cor_2 = cor(data_8$model, data_8$mean_human, method="pearson")
ci_2 = compute_bootstrap(data_8)
ci_2[4]
ci_2[5]
```

The Pearson correlation is `r cor(data_8$model, data_8$mean_human, method="pearson")` (95% CI: `r paste(ci_cor[4], "-", ci_cor[5], sep="")`.

## TEMP

```{r}
cor_2 = cor(data_8$model, data_8$mean_human, method="pearson")

cor_2 = round(cor(data_8$model, data_8$mean_human, method="pearson"), 2)
annotation_0 = data.frame(
  label = paste("r = ", cor_2, " (95% CI: 0.91 - 0.96)", sep=""),
  x = c(0.40),
  y = c(0.75)
)
geom_text_size = (5/14) * 10

figure_2a = data_8 %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  geom_point(aes(fill=type), color="black", pch=21, size=1.5, alpha=0.6) +
  # geom_text(vjust=-1.0, hjust=-1.0) +
  geom_smooth(method="lm", se=TRUE, linetype="dashed", color="black") +
  geom_text(data=annotation_0, aes(x=x, y=y, label=label), color="black", size=geom_text_size) +
  # ggtitle("Model Predictions vs. Participant Judgments") +
  xlab("Model Predictions") +
  # xlim(0, 1) +
  # ylim(0, 1) +
  # scale_x_discrete(name="Model Predictions",
  #                  )
  ylab("Participant Judgments") +
  scale_fill_discrete(name="Inference Type:",
                       limits=c("entrance", "goal"),
                       labels=c("Entrance", "Goal")) +
  theme_classic() +
  theme(aspect.ratio=1,
        legend.position="right",
        legend.title=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=10),
        axis.text=element_text(size=9))
ggsave("writing/CogSci 2020/figures/figure_2a2.pdf", device="pdf", plot=figure_2a,
       width=3.375, units="in")

# figure_2b = data_4 %>%
#   ggplot(aes(x=model, y=mean_human, label=map)) +
#   geom_point(aes(color=substr(map, 0, 2)), size=2) +
#   # geom_text(vjust=-1.0) +
#   geom_smooth(method="lm", se=TRUE, linetype="dashed", color="black") +
#   # geom_abline() +
#   xlab("Model Predictions") +
#   ylab("Participant Judgments") +
#   scale_color_discrete(name="Grid-world Type:") +
#   theme_classic() +
#   theme(legend.position="bottom",
#         legend.title=element_text(size=10),
#         legend.text=element_text(size=10),
#         axis.title=element_text(size=10),
#         axis.text=element_text(size=9))

# cor_2 = round(cor(data_8$model, data_8$mean_human, method="pearson"), 2)
annotation_1 = data.frame(
  label = paste("r = 0.80 (95% CI: 0.29 - 0.94)", sep=""),
  x = c(0.6),
  y = c(0.8)
)

new_fig = figure_2b + 
  geom_text(data=annotation_1, aes(x=x, y=y, label=label), color="black", size=geom_text_size) + 
  scale_color_discrete(name="Inference Type:") + 
  geom_point(aes(color=substr(map, 0, 2)), color="black", pch=21, size=2)
library(cowplot)
figure_2 = plot_grid(figure_2a, new_fig, nrow=1, rel_widths=c(0.51, 0.49))
figure_2
ggsave("writing/CogSci 2020/figures/new_plot.pdf", device="pdf", plot=figure_2b,
       # width=6.5, height=5.07, units="in")
       width=3.375, height=2.535, units="in")

# output at 3.375 in width
# scatter_plot
```

Now let's see if we can predict the model error based on how many doors there are in the task. We'll first start with goal inferences.

```{r}
plot_5 = data_5 %>%
  mutate(num_doors=ifelse(grepl("ND", substr(map, 1, 2)), 1,
                          ifelse(grepl("DX|NX", substr(map, 1, 2)), 2, 3))) %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  # geom_point(aes(color=substr(map, 0, 2))) +
  geom_point(aes(color=factor(num_doors))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Goal Predictions vs. Participant Goal Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Goal") + 
  theme_classic() +
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5)) +
  labs(color="Doors")
plot_5
```

There doesn't seem to be anything here, so let's try running a linear regression. 

```{r}
temp_2 = data_4 %>%
  left_join(model_1) %>%
  mutate(model_error=human-model) %>%
  mutate(num_doors=ifelse(grepl("ND", substr(map, 1, 2)), 1,
                          ifelse(grepl("DX|NX", substr(map, 1, 2)), 2, 3)))
m_0 = lm(formula=model_error~num_doors, data=temp_2)
summary(m_0)
```

We can do the same thing for entrance inferences.

```{r}
plot_6 = data_7 %>%
  mutate(num_doors=ifelse(grepl("ND", substr(map, 1, 2)), 1,
                          ifelse(grepl("DX|NX", substr(map, 1, 2)), 2, 3))) %>%
  ggplot(aes(x=model, y=mean_human, label=map)) +
  # geom_point(aes(color=substr(map, 0, 2))) +
  geom_point(aes(color=factor(num_doors))) +
  # geom_text(vjust=-1.0) +
  geom_smooth(method="lm", se=FALSE, linetype="dashed", color="grey") +
  ggtitle("Model Entrance Predictions vs. Participant Entrance Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Entrance") +
  theme_classic() + 
  theme(plot.title=element_text(hjust=0.5),
        legend.title=element_text(hjust=0.5))
plot_6
```

## Alternative Model

```{r}
# Door_d: x1, x2, x3, ...
# Goal_d: y1, y2, y3, ...
data_9 = read_csv("imageinferencedata.csv")
# Goal: A, B, C
library(lmerTest)
library(nnet)
data_10 = data_9 %>%
  mutate()
model = glm(data=data_9, max(mean_A, mean_B, mean_C) ~ A_d*B_d*C_d + `1_d`)
summary(model)
```


```{r, eval=FALSE, include=FALSE}
data_4 %>% 
  rename(type=goal) %>% 
  rbind(rename(data_5, type=entrance)) %>% 
  ggplot(aes(x=model, y=mean_human, label=map)) + 
  geom_point(aes(color=type)) +
  geom_smooth(method="lm") + 
  # ggtitle("Model Entrance Predictions vs. Participant Entrance Judgments") +
  xlab("Model Predictions") +
  ylab("Human Judgments") +
  scale_color_discrete(name="Type") +
  theme_classic()

library(corrplot)
data_3 %>%
  filter(map=="ND_PX_1") %>%
  select(map, A, B, C, unique_id) %>%
  gather(goal, value, A, B, C) %>%
  ggplot(aes(x=value, fill=goal)) +
  geom_density(alpha=0.33) +
  facet_wrap(~map)
  # mutate(full_id=paste(map, goal, sep="_")) %>%
  # select(-map, -goal) %>%
  # spread(unique_id, value) %>%
  # select(-full_id) %>%
  # cor()
  # 
  # corrplot()
```