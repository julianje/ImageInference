---
title: "Image Inference - Experiment 2"
output:
  html_document:
    code_folding: hide
    df_print: paged
  pdf_document: default
---
  
```{r setup, echo=FALSE}
# Set the working directory.
knitr::opts_knit$set(root.dir=normalizePath("../.."))

# Turn off compile messages and warnings.
knitr::opts_chunk$set(message=FALSE, warning=FALSE)

# Set up which data iteration we're analyzing.
data = "pilot_0"

# Set up the path to the participant and model data.
human_path = file.path("data/experiment_2/human", data)
model_path = file.path("data/experiment_2/model", data)
```

```{r libraries, echo=FALSE}
# Import R libraries.
library(jsonlite)
library(tidyverse)
```

# Preprocessing

```{r preprocessing}
# Read in the participant data (after manually removing errors).
data_0 = read_csv(file.path(human_path, "data.csv"), quote="~")

# Read in the MTurk results file.
mturk_results = read_csv(file.path(human_path, "mturk_results.csv"), col_names=TRUE) %>%
  mutate(Answer.surveycode=substr(Answer.surveycode, 6, length(Answer.surveycode))) %>%
  filter(AssignmentStatus=="Approved")

# Check for invalid survey codes.
invalid = sum(!(mturk_results$Answer.surveycode %in% data_0$unique_id))
if (invalid != 0) { stop("There's an invalid survey code.") }

# Extract the trial information for each participant and save it.
for (p in 1:length(mturk_results$Answer.surveycode)) {
  # Find the database entry that contains the experiment code that this 
  # participant submitted.
  data_1 = data_0 %>%
    filter(unique_id==mturk_results$Answer.surveycode[p]) %>%
    filter(nchar(results)==min(nchar(results)))
  
  # Extract the experiment code that this participant submitted.
  experiment_code = substr(fromJSON(data_1$results)$catch_trials$experiment_code, 6, 13)

  # Find the database entry that contains the trial information for this 
  # participant.
  data_2 = data_0 %>%
    filter(unique_id==experiment_code) %>%
    filter(nchar(results)==max(nchar(results)))
  
  # Convert the JSON string to a data frame and refactor.
  data_3 = fromJSON(data_2$results)$trials %>%
    select(-trial_num) %>%
    mutate(participant=as.character(p-1)) %>%
    select(participant, map, coords)

  # Save the trial information for this participant.
  write_csv(data_3, file.path(human_path, paste(p-1, ".csv", sep="")))
}
```

# Model Comparison

We pass in the trial information to both our model and an alternative model and compute the Bayes factor. A Bayes factor greater than one indicates our model explains participant judgments better; a Bayes factor less than one indicates the alternative model explains participant judgments better.

```{r, echo=FALSE}
# Read in the model evaluations of the participant-generated paths.
data_0 = read_csv(file.path(model_path, "bayes_factors.csv"))

# Compute the mean Bayes factor within participants.
data_1 = data_0 %>%
  group_by(participant) %>%
  summarize(mean_bayes_factor=mean(bayes_factor))

# Run a t-test with the null hypothesis that the true Bayes factor is 1.
t.test(x=data_1$mean_bayes_factor, mu=1.0, alternative="greater")
```
